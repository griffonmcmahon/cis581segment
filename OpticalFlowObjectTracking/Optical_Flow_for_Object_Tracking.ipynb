{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optical Flow for Object Tracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Detectron2 Beginner's Tutorial\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
        "* Run inference on images or videos, with an existing detectron2 model\n",
        "* Train a detectron2 model on a new dataset\n",
        "\n",
        "You can make a copy of this tutorial by \"File -> Open in playground mode\" and play with it yourself. __DO NOT__ request access to this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86def658-78c2-4d62-b925-7da3036e35c8"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1 'pycocotools>=2.0.1'\n",
        "#!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "#!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1) (3.2.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1) (50.3.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools>=2.0.1) (1.15.0)\n",
            "1.7.0+cu101 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36848ec4-3fb3-46a4-b4dd-3968a441baf2"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "#assert torch.__version__.startswith(\"1.6\")\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.3+cu101)\n",
            "Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.2.post20201122)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (8.0.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.8)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (2.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->detectron2) (2.4.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.3.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.35.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (2.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz9zQXn3plrI"
      },
      "source": [
        "import time\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import logging\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkJSSuKbohZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad75576-e79b-45ca-fe3f-24292aba25cf"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5qnQDv920iv"
      },
      "source": [
        "from fvcore.common.file_io import PathManager\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#datalabels=load_sem_seg(annotations, images_dir, gt_ext=\"png\", image_ext=\"png\")\n",
        "\n",
        "\n",
        "##images_dir = \"/content/drive/My Drive/CIS581/FinalProject/Kitti/train_images/image_2\"\n",
        "#annotations=\"/content/drive/My Drive/CIS581/FinalProject/Kitti/trainingmask/\"\n",
        "\n",
        "images_dir = \"/content/drive/My Drive/CIS581/ImageSegmentation/bdd/bdd100k/seg/images/train/\"\n",
        "annotations=\"/content/drive/My Drive/CIS581/ImageSegmentation/bdd/bdd100k/seg/labels/train/\"\n",
        "json_fileloc=\"/content/drive/My Drive/CIS581/ImageSegmentation/bdd/training_corrected_1000v2.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39TaS1PdxoUH"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train5\", {}, \"/content/drive/My Drive/CIS581/ImageSegmentation/bdd/training_corrected_1000v2.json\",images_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r8J3lu39zru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f91737-df4b-4510-b32b-20744378b45c"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train5\",)\n",
        "cfg.DATASETS.TEST = ()#\"my_dataset_val3\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")#\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")   #\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.00075  #0.00025  # pick a good LR\n",
        "\n",
        "cfg.SOLVER.WARMUP_ITERS=500\n",
        "cfg.SOLVER.MAX_ITER = 1000   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "\n",
        "#cfg.SOLVER.STEPS=(10,15)\n",
        "#cfg.SOLVER.GAMMA=0.05\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 #128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 14  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "\n",
        "#cfg.TEST.EVAL_PERIOD=500\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[11/24 19:16:01 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=56, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/24 19:16:02 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[11/24 19:16:02 d2.data.datasets.coco]: \u001b[0mLoaded 999 images in COCO format from /content/drive/My Drive/CIS581/ImageSegmentation/bdd/training_corrected_1000v2.json\n",
            "\u001b[32m[11/24 19:16:02 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 999 images left.\n",
            "\u001b[32m[11/24 19:16:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[11/24 19:16:02 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[11/24 19:16:02 d2.data.common]: \u001b[0mSerializing 999 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[11/24 19:16:02 d2.data.common]: \u001b[0mSerialized dataset takes 23.38 MiB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (56, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (56,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[11/24 19:16:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:217: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  num_fg = fg_inds.nonzero().numel()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[11/24 19:16:22 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 19  total_loss: 6.4  loss_cls: 2.731  loss_box_reg: 0.6493  loss_mask: 0.6937  loss_rpn_cls: 1.479  loss_rpn_loc: 0.8201  time: 0.8951  data_time: 0.5667  lr: 2.9221e-05  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:16:38 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 39  total_loss: 5.273  loss_cls: 2.222  loss_box_reg: 0.5749  loss_mask: 0.6862  loss_rpn_cls: 0.786  loss_rpn_loc: 0.8682  time: 0.8335  data_time: 0.3667  lr: 5.9192e-05  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:16:56 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 59  total_loss: 3.799  loss_cls: 1.31  loss_box_reg: 0.5219  loss_mask: 0.6776  loss_rpn_cls: 0.4443  loss_rpn_loc: 0.7878  time: 0.8645  data_time: 0.5444  lr: 8.9161e-05  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:17:16 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 79  total_loss: 3.436  loss_cls: 1.134  loss_box_reg: 0.5358  loss_mask: 0.6651  loss_rpn_cls: 0.3054  loss_rpn_loc: 0.7985  time: 0.8938  data_time: 0.5879  lr: 0.00011913  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:17:33 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 99  total_loss: 3.412  loss_cls: 1.091  loss_box_reg: 0.6116  loss_mask: 0.649  loss_rpn_cls: 0.2573  loss_rpn_loc: 0.767  time: 0.8857  data_time: 0.4665  lr: 0.0001491  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:17:49 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 119  total_loss: 3.373  loss_cls: 1.07  loss_box_reg: 0.5968  loss_mask: 0.6383  loss_rpn_cls: 0.2636  loss_rpn_loc: 0.7911  time: 0.8725  data_time: 0.4047  lr: 0.00017907  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:18:07 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 139  total_loss: 3.305  loss_cls: 1.036  loss_box_reg: 0.6314  loss_mask: 0.6262  loss_rpn_cls: 0.2449  loss_rpn_loc: 0.754  time: 0.8797  data_time: 0.5384  lr: 0.00020904  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:18:25 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 159  total_loss: 3.203  loss_cls: 1.008  loss_box_reg: 0.6298  loss_mask: 0.6019  loss_rpn_cls: 0.2308  loss_rpn_loc: 0.6933  time: 0.8772  data_time: 0.4653  lr: 0.00023901  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:18:43 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 179  total_loss: 3.14  loss_cls: 0.9821  loss_box_reg: 0.6244  loss_mask: 0.5846  loss_rpn_cls: 0.2314  loss_rpn_loc: 0.7272  time: 0.8810  data_time: 0.5293  lr: 0.00026898  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:19:02 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 199  total_loss: 3.031  loss_cls: 0.9281  loss_box_reg: 0.631  loss_mask: 0.5757  loss_rpn_cls: 0.2125  loss_rpn_loc: 0.6948  time: 0.8872  data_time: 0.5536  lr: 0.00029895  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:19:19 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 219  total_loss: 3.044  loss_cls: 0.9375  loss_box_reg: 0.6319  loss_mask: 0.568  loss_rpn_cls: 0.1967  loss_rpn_loc: 0.6992  time: 0.8831  data_time: 0.4558  lr: 0.00032892  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:19:36 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 239  total_loss: 2.909  loss_cls: 0.8836  loss_box_reg: 0.6043  loss_mask: 0.534  loss_rpn_cls: 0.2005  loss_rpn_loc: 0.7273  time: 0.8805  data_time: 0.4560  lr: 0.00035889  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:19:52 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 259  total_loss: 2.82  loss_cls: 0.8372  loss_box_reg: 0.6322  loss_mask: 0.5094  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.6901  time: 0.8739  data_time: 0.2817  lr: 0.00038886  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:20:04 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 279  total_loss: 2.857  loss_cls: 0.8012  loss_box_reg: 0.6371  loss_mask: 0.4926  loss_rpn_cls: 0.2193  loss_rpn_loc: 0.7955  time: 0.8570  data_time: 0.0155  lr: 0.00041883  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:20:17 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 299  total_loss: 2.827  loss_cls: 0.7988  loss_box_reg: 0.6534  loss_mask: 0.4823  loss_rpn_cls: 0.1904  loss_rpn_loc: 0.7262  time: 0.8422  data_time: 0.0120  lr: 0.0004488  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:20:30 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 319  total_loss: 2.813  loss_cls: 0.7931  loss_box_reg: 0.6177  loss_mask: 0.4878  loss_rpn_cls: 0.2225  loss_rpn_loc: 0.7314  time: 0.8296  data_time: 0.0177  lr: 0.00047877  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:20:43 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 339  total_loss: 2.743  loss_cls: 0.7301  loss_box_reg: 0.657  loss_mask: 0.4563  loss_rpn_cls: 0.2123  loss_rpn_loc: 0.6756  time: 0.8183  data_time: 0.0140  lr: 0.00050874  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:20:56 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 359  total_loss: 2.752  loss_cls: 0.7216  loss_box_reg: 0.6393  loss_mask: 0.4564  loss_rpn_cls: 0.2036  loss_rpn_loc: 0.7338  time: 0.8084  data_time: 0.0149  lr: 0.00053871  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:21:08 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 379  total_loss: 2.712  loss_cls: 0.688  loss_box_reg: 0.6161  loss_mask: 0.4508  loss_rpn_cls: 0.2006  loss_rpn_loc: 0.7159  time: 0.7994  data_time: 0.0138  lr: 0.00056868  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:21:21 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 399  total_loss: 2.627  loss_cls: 0.6922  loss_box_reg: 0.639  loss_mask: 0.4297  loss_rpn_cls: 0.2022  loss_rpn_loc: 0.6447  time: 0.7916  data_time: 0.0188  lr: 0.00059865  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:21:34 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 419  total_loss: 2.591  loss_cls: 0.678  loss_box_reg: 0.6203  loss_mask: 0.4344  loss_rpn_cls: 0.1959  loss_rpn_loc: 0.7052  time: 0.7848  data_time: 0.0163  lr: 0.00062862  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:21:47 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 439  total_loss: 2.553  loss_cls: 0.645  loss_box_reg: 0.6114  loss_mask: 0.411  loss_rpn_cls: 0.1815  loss_rpn_loc: 0.6962  time: 0.7783  data_time: 0.0143  lr: 0.00065859  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:22:00 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 459  total_loss: 2.513  loss_cls: 0.6447  loss_box_reg: 0.6172  loss_mask: 0.4032  loss_rpn_cls: 0.1804  loss_rpn_loc: 0.6689  time: 0.7721  data_time: 0.0158  lr: 0.00068856  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:22:13 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 479  total_loss: 2.508  loss_cls: 0.605  loss_box_reg: 0.6153  loss_mask: 0.4021  loss_rpn_cls: 0.1583  loss_rpn_loc: 0.6849  time: 0.7667  data_time: 0.0176  lr: 0.00071853  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:22:26 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 499  total_loss: 2.442  loss_cls: 0.5863  loss_box_reg: 0.5894  loss_mask: 0.3858  loss_rpn_cls: 0.195  loss_rpn_loc: 0.6659  time: 0.7616  data_time: 0.0121  lr: 0.0007485  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:22:38 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 519  total_loss: 2.41  loss_cls: 0.5925  loss_box_reg: 0.6128  loss_mask: 0.3847  loss_rpn_cls: 0.1785  loss_rpn_loc: 0.6912  time: 0.7569  data_time: 0.0158  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:22:51 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 539  total_loss: 2.443  loss_cls: 0.6  loss_box_reg: 0.58  loss_mask: 0.3836  loss_rpn_cls: 0.174  loss_rpn_loc: 0.6499  time: 0.7528  data_time: 0.0219  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:23:04 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 559  total_loss: 2.459  loss_cls: 0.5959  loss_box_reg: 0.5868  loss_mask: 0.3719  loss_rpn_cls: 0.1887  loss_rpn_loc: 0.6833  time: 0.7488  data_time: 0.0164  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:23:17 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 579  total_loss: 2.422  loss_cls: 0.5765  loss_box_reg: 0.5807  loss_mask: 0.3749  loss_rpn_cls: 0.17  loss_rpn_loc: 0.6887  time: 0.7452  data_time: 0.0151  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:23:30 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 599  total_loss: 2.503  loss_cls: 0.5683  loss_box_reg: 0.5976  loss_mask: 0.3571  loss_rpn_cls: 0.1804  loss_rpn_loc: 0.7284  time: 0.7418  data_time: 0.0177  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:23:43 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 619  total_loss: 2.353  loss_cls: 0.5789  loss_box_reg: 0.613  loss_mask: 0.3521  loss_rpn_cls: 0.1855  loss_rpn_loc: 0.6393  time: 0.7385  data_time: 0.0109  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:23:55 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 639  total_loss: 2.311  loss_cls: 0.5494  loss_box_reg: 0.5744  loss_mask: 0.3577  loss_rpn_cls: 0.1732  loss_rpn_loc: 0.6492  time: 0.7351  data_time: 0.0155  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:24:08 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 659  total_loss: 2.317  loss_cls: 0.5521  loss_box_reg: 0.5407  loss_mask: 0.3558  loss_rpn_cls: 0.1691  loss_rpn_loc: 0.6929  time: 0.7321  data_time: 0.0178  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:24:21 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 679  total_loss: 2.367  loss_cls: 0.5593  loss_box_reg: 0.5688  loss_mask: 0.3588  loss_rpn_cls: 0.1667  loss_rpn_loc: 0.6839  time: 0.7294  data_time: 0.0131  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:24:34 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 699  total_loss: 2.359  loss_cls: 0.5582  loss_box_reg: 0.5407  loss_mask: 0.3589  loss_rpn_cls: 0.1682  loss_rpn_loc: 0.6694  time: 0.7269  data_time: 0.0172  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:24:47 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 719  total_loss: 2.402  loss_cls: 0.5624  loss_box_reg: 0.5736  loss_mask: 0.3851  loss_rpn_cls: 0.2071  loss_rpn_loc: 0.6763  time: 0.7245  data_time: 0.0135  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:24:59 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 739  total_loss: 2.287  loss_cls: 0.5566  loss_box_reg: 0.5551  loss_mask: 0.3549  loss_rpn_cls: 0.1735  loss_rpn_loc: 0.6782  time: 0.7221  data_time: 0.0149  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:25:12 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 759  total_loss: 2.374  loss_cls: 0.5626  loss_box_reg: 0.5362  loss_mask: 0.3543  loss_rpn_cls: 0.1727  loss_rpn_loc: 0.677  time: 0.7200  data_time: 0.0181  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:25:25 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 779  total_loss: 2.314  loss_cls: 0.5383  loss_box_reg: 0.5631  loss_mask: 0.3504  loss_rpn_cls: 0.1681  loss_rpn_loc: 0.6816  time: 0.7179  data_time: 0.0150  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:25:38 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 799  total_loss: 2.306  loss_cls: 0.5357  loss_box_reg: 0.5485  loss_mask: 0.3463  loss_rpn_cls: 0.1682  loss_rpn_loc: 0.6869  time: 0.7160  data_time: 0.0187  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:25:51 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 819  total_loss: 2.208  loss_cls: 0.5356  loss_box_reg: 0.5418  loss_mask: 0.3606  loss_rpn_cls: 0.1677  loss_rpn_loc: 0.5993  time: 0.7142  data_time: 0.0162  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:26:04 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 839  total_loss: 2.244  loss_cls: 0.5311  loss_box_reg: 0.524  loss_mask: 0.3495  loss_rpn_cls: 0.1635  loss_rpn_loc: 0.6319  time: 0.7126  data_time: 0.0118  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:26:16 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 859  total_loss: 2.306  loss_cls: 0.5321  loss_box_reg: 0.5539  loss_mask: 0.3471  loss_rpn_cls: 0.1506  loss_rpn_loc: 0.7005  time: 0.7107  data_time: 0.0167  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:26:29 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 879  total_loss: 2.278  loss_cls: 0.5284  loss_box_reg: 0.5622  loss_mask: 0.3469  loss_rpn_cls: 0.1755  loss_rpn_loc: 0.6378  time: 0.7092  data_time: 0.0205  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:26:42 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 899  total_loss: 2.249  loss_cls: 0.514  loss_box_reg: 0.5289  loss_mask: 0.3443  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.6471  time: 0.7077  data_time: 0.0125  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:26:55 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 919  total_loss: 2.298  loss_cls: 0.5447  loss_box_reg: 0.528  loss_mask: 0.3474  loss_rpn_cls: 0.1774  loss_rpn_loc: 0.6431  time: 0.7063  data_time: 0.0184  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:27:08 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 939  total_loss: 2.32  loss_cls: 0.5303  loss_box_reg: 0.531  loss_mask: 0.3458  loss_rpn_cls: 0.1525  loss_rpn_loc: 0.6891  time: 0.7049  data_time: 0.0164  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:27:21 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 959  total_loss: 2.302  loss_cls: 0.5308  loss_box_reg: 0.5287  loss_mask: 0.3479  loss_rpn_cls: 0.1756  loss_rpn_loc: 0.7173  time: 0.7036  data_time: 0.0142  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:27:33 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 979  total_loss: 2.228  loss_cls: 0.5204  loss_box_reg: 0.544  loss_mask: 0.3387  loss_rpn_cls: 0.1697  loss_rpn_loc: 0.6701  time: 0.7023  data_time: 0.0180  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:27:48 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 2.217  loss_cls: 0.5099  loss_box_reg: 0.525  loss_mask: 0.3354  loss_rpn_cls: 0.1573  loss_rpn_loc: 0.6642  time: 0.7012  data_time: 0.0140  lr: 0.00075  max_mem: 4990M\n",
            "\u001b[32m[11/24 19:27:48 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:11:39 (0.7012 s / it)\n",
            "\u001b[32m[11/24 19:27:48 d2.engine.hooks]: \u001b[0mTotal training time: 0:11:42 (0:00:02 on hooks)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w9OqT2QqbgO"
      },
      "source": [
        "!cp 'output/model_final.pth' '/content/drive/My Drive/CIS581/ImageSegmentation/model/outputfile.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhYqN8x7rabo"
      },
      "source": [
        "#To load a model run:\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 14\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "cfg.MODEL.WEIGHTS =\"/content/drive/My Drive/CIS581/ImageSegmentation/model/outputfile.pth\"# path to the model we trained\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86C36DEFDUzH"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "#predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2bszRBvCRzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bcddba-ada7-4da9-f4f1-cdf4f09de008"
      },
      "source": [
        "%cd /content/drive/My Drive/CIS581/ImageSegmentation"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CIS581/ImageSegmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ZeS_RxR7QY"
      },
      "source": [
        "#optical flow for mask\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "from skimage import img_as_ubyte\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "from optical_flow import *\n",
        "\n",
        "def objectTrackingNew(rawVideo):\n",
        "    \"\"\"\n",
        "\n",
        "        Description: Generate and save tracking video\n",
        "        Input:\n",
        "        rawVideo: Raw video file name, String\n",
        "        Instruction: Please feel free to use cv.selectROI() to manually select bounding box\n",
        "\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(rawVideo)\n",
        "    imgs = []\n",
        "    frame_cnt = 0\n",
        "    \n",
        "    #random colors for 14 classes\n",
        "    colors = [tuple(np.random.randint(256, size=3)) for _ in range(14)]\n",
        "    print(len(colors))\n",
        "    # Initialize video writer for tracking video\n",
        "    trackVideo = '/content/drive/My Drive/CIS581/ImageSegmentation/optresults/Output1.mov'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    size = (int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
        "    #size = (int(cap.get(360)), int(cap.get(480)))\n",
        "    writer = cv2.VideoWriter(trackVideo, fourcc, fps, size)\n",
        "\n",
        "    #max number of features you will extract\n",
        "    N=5\n",
        "\n",
        "    #Lucas Kanade param\n",
        "    # lk_params = dict( winSize  = (35,35),\n",
        "    #               maxLevel = 5,\n",
        "    #               criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "    #variables\n",
        "    old_classes=np.array([])\n",
        "    old_count=0\n",
        "    old_masks=[]\n",
        "    old_coords=np.array([])\n",
        "    initNF=[]\n",
        "    #trajectoryX,trajectoryY=np.array([]),np.array([])\n",
        "    while (cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        #rotate the video frame \n",
        "        frame=np.rot90(frame)\n",
        "        #writing video on vis\n",
        "        vis = frame.copy() \n",
        "        #frames used for feature translation\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255 \n",
        "        frame_cnt += 1\n",
        "        #if frame_cnt<11:\n",
        "        #  continue\n",
        "        H,W = vis.shape[0],vis.shape[1]\n",
        "        outputs = predictor(vis)\n",
        "        v = Visualizer(vis[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.85)\n",
        "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "        \n",
        "        newimage=np.zeros((H,W))\n",
        "        count=outputs[\"instances\"].to(\"cpu\").pred_classes.numpy().shape\n",
        "        \n",
        "        #put mask on frame using detectron2 visualizer\n",
        "        for i in range(count[0]):\n",
        "          mask=outputs[\"instances\"].to(\"cpu\").pred_masks.numpy()[i].astype(int)*(i+1)\n",
        "          #use current instance's class id to get corresponding color\n",
        "          class_num=outputs[\"instances\"].pred_classes[i]\n",
        "          color=colors[class_num]\n",
        "          for n in range(3):\n",
        "            vis[:, :, n] = np.where(mask!= 0, (vis[:, :, n] * 0.5 + 0.5*color[n]),vis[:, :, n])\n",
        "        \n",
        "        cv2.imwrite('/content/drive/My Drive/CIS581/ImageSegmentation/optresults/{}_1.jpg'.format(frame_cnt), img_as_ubyte(vis))\n",
        "        \n",
        "\n",
        "        if frame_cnt==1:\n",
        "          #save first frame's features, bboxes, mask coordinates, count, and classes\n",
        "          bboxes=outputs[\"instances\"].to(\"cpu\").pred_boxes.tensor.numpy()\n",
        "          num=bboxes.shape[0]\n",
        "          bboxes=bboxes.reshape(num,2,2)\n",
        "          initNF,features=getFeatures(frame,bboxes,N)\n",
        "          old_classes=outputs[\"instances\"].to(\"cpu\").pred_classes.numpy()\n",
        "          old_bboxes=bboxes\n",
        "          old_masks=outputs[\"instances\"].to(\"cpu\").pred_masks.numpy()\n",
        "          old_coords=generateAllCoordinates(old_masks,W,H)\n",
        "          old_count=count[0]\n",
        "        else:\n",
        "          all_count=0\n",
        "          all_bboxes,all_masks,all_features,all_masks,all_coords,all_classes = np.array([]),np.array([]),np.array([]),np.array([]),np.array([]),[]\n",
        "          all_featNum=[]\n",
        "          #current frame's class dictionary -> key: class, value: number of class\n",
        "          new_classes=outputs[\"instances\"].to(\"cpu\").pred_classes.numpy()\n",
        "          unique, counts = np.unique(new_classes, return_counts=True)\n",
        "          dictC=dict(zip(unique, counts)) \n",
        "          print(\"ALL classes\",all_classes)\n",
        "          print(\"old count\",old_count,\" and count\",count)\n",
        "          print(\"old classes\",old_classes)\n",
        "          for k in range(old_count):\n",
        "            print(count[0],\"running:\",k)\n",
        "            cnt=0\n",
        "            if old_classes[k]!= 9 and old_classes[k]!=3 and old_classes[k]!=12:\n",
        "              #we are generating masks only on human and cars\n",
        "              continue\n",
        "            if old_classes[k] not in new_classes:\n",
        "              #class from previous frames are not detected in current frame -> optical flow to generate mask\n",
        "              print(\"class\",old_classes[k],\" not found\")\n",
        "              all_featNum,all_features,all_bboxes, coord,all_coords,all_classes, eraseObject=transformMask(initNF[k],frame,frame_old,all_featNum, all_features,all_bboxes,all_coords,all_classes,features[k],old_bboxes[k],old_coords[k],old_classes[k],H,W,N)\n",
        "              if eraseObject==False:\n",
        "                tmp_coord=coord.reshape(H*W,2)\n",
        "                #generate mask on the frame with the transformed coordinates\n",
        "                mask=generateMaskWithCoordinates(tmp_coord,W,H)\n",
        "                color=colors[int(old_classes[k])]\n",
        "                for n in range(3):\n",
        "                  vis[:, :, n] = np.where(mask!= 0, (vis[:, :, n] * 0.5 + 0.5*color[n]),vis[:, :, n])\n",
        "                all_count+=1\n",
        "              continue\n",
        "            for j in range(count[0]):\n",
        "              class_num=new_classes[j]\n",
        "              mask=outputs[\"instances\"].to(\"cpu\").pred_masks.numpy()[j].astype(int)*(i+1)\n",
        "              print(\"DICT\",dictC )\n",
        "              print(\"Class Num:\",class_num,type(class_num))\n",
        "              print(\"get\",dictC.get(class_num.item()),\" K\",k)\n",
        "              if old_classes[k]==class_num:\n",
        "                old_mask=generateMaskWithCoordinates(old_coords[k],W,H)\n",
        "                intersect=np.logical_and(old_mask,mask)\n",
        "                interNum=np.count_nonzero(intersect)\n",
        "                maskNum=np.count_nonzero(old_mask)\n",
        "                print(\"InterNum \",interNum,\" maskNum \",maskNum)\n",
        "                if interNum>=0.5*maskNum:\n",
        "                  print(\"masks match\")\n",
        "                  break\n",
        "                else:\n",
        "                  cnt+=1\n",
        "                  if (dictC.get(class_num.item())>cnt):\n",
        "                    print(\"masks do not match but will have to look more : cnt\",cnt)\n",
        "                    pass\n",
        "                  else:\n",
        "                    print(\"masks do not match : optical flow to put mask on pic\")\n",
        "                    all_featNum,all_features,all_bboxes, coord,all_coords,all_classes, eraseObject=transformMask(initNF[k],frame,frame_old,all_featNum, all_features,all_bboxes,all_coords,all_classes,features[k],old_bboxes[k],old_coords[k],old_classes[k],H,W,N)\n",
        "                    if eraseObject==False:\n",
        "                      tmp_coord=coord.reshape(H*W,2)\n",
        "                      mask=generateMaskWithCoordinates(tmp_coord,W,H)\n",
        "                      color=colors[int(old_classes[k])]\n",
        "                      for n in range(3):\n",
        "                        vis[:, :, n] = np.where(mask!= 0, (vis[:, :, n] * 0.5 + 0.5*color[n]),vis[:, :, n])\n",
        "                      all_count+=1\n",
        "          print(\"Count\",all_count)\n",
        "          print(\"########save frame\",frame_cnt,\"###########\")\n",
        "          bboxes=outputs[\"instances\"].to(\"cpu\").pred_boxes.tensor.numpy()\n",
        "          num=bboxes.shape[0]\n",
        "          bboxes=bboxes.reshape(num,2,2)\n",
        "          masks=outputs[\"instances\"].to(\"cpu\").pred_masks.numpy()\n",
        "          if all_count>0:\n",
        "            #optical flow was used at least once, save feature points, classes, mask coordinates, bboxes from previous frames and current frame\n",
        "            old_count=all_count+count[0]\n",
        "            old_classes=np.append(np.array(all_classes),new_classes)\n",
        "            tmp_coords=generateAllCoordinates(masks,W,H)\n",
        "            old_coords=np.append(all_coords,tmp_coords)\n",
        "            old_bboxes=np.append(all_bboxes,bboxes)\n",
        "            numF,features=getFeatures(frame,bboxes,N)\n",
        "            initNF=np.append(all_featNum,numF)\n",
        "            features=np.append(all_features,features)\n",
        "          elif all_count==0:\n",
        "            #no optical flow was used, save only current frame's feature points, bboxes, masks, count, and classes\n",
        "            numF,features=getFeatures(frame,bboxes,N)\n",
        "            old_classes=new_classes\n",
        "            initNF=numF\n",
        "            old_bboxes=bboxes\n",
        "            tmp_coords=generateAllCoordinates(masks,W,H)\n",
        "            old_coords=np.append(all_coords,tmp_coords)\n",
        "            old_count=count[0]\n",
        "        #reshaping coordinates, bboxes, features\n",
        "          old_coords=old_coords.reshape((old_count,H*W,2))\n",
        "          old_bboxes=old_bboxes.reshape((old_count,2,2))\n",
        "          features=features.reshape((old_count,N,2))\n",
        "\n",
        "        #save frame   \n",
        "        frame_old=frame.copy()\n",
        "        # save to list\n",
        "        imgs.append(img_as_ubyte(vis))\n",
        "        \n",
        "        # save image \n",
        "        #if (frame_cnt + 1) % 2 == 0:\n",
        "        cv2.imwrite('/content/drive/My Drive/CIS581/ImageSegmentation/optresults/{}_2.jpg'.format(frame_cnt), img_as_ubyte(vis))\n",
        "        \n",
        "        # Save video\n",
        "        writer.write(vis)\n",
        "        #if (frame_cnt==50):\n",
        "          #break\n",
        "        \n",
        "    # Release video reader and video writer\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    \n",
        "    return\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfxvlbEyQDpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a228e6d5-3e11-4d0c-fbf2-0205ca02026b"
      },
      "source": [
        "rawVideo = \"/content/drive/My Drive/CIS581/ImageSegmentation/test videos/cabc30fc-eb673c5a.mov\"\n",
        "if not os.path.exists(\"/content/drive/My Drive/CIS581/ImageSegmentation/optresults\"): os.mkdir(\"/content/drive/My Drive/CIS581/ImageSegmentation/optresults\")\n",
        "objectTrackingNew(rawVideo)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "ALL classes []\n",
            "old count 9  and count (8,)\n",
            "old classes [4 2 9 9 1 9 1 8 1]\n",
            "8 running: 0\n",
            "8 running: 1\n",
            "8 running: 2\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 4 <class 'numpy.int64'>\n",
            "get 1  K 2\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 2 <class 'numpy.int64'>\n",
            "get 1  K 2\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 2\n",
            "InterNum  24469  maskNum  26096\n",
            "masks match\n",
            "8 running: 3\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 4 <class 'numpy.int64'>\n",
            "get 1  K 3\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 2 <class 'numpy.int64'>\n",
            "get 1  K 3\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 3\n",
            "InterNum  734  maskNum  11057\n",
            "masks do not match but will have to look more : cnt 1\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 1 <class 'numpy.int64'>\n",
            "get 2  K 3\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 3\n",
            "InterNum  0  maskNum  11057\n",
            "masks do not match : optical flow to put mask on pic\n",
            "Transform mask: feature points (0,)\n",
            "Similarity Transform\n",
            "Before transforming: Non zero  [[ 68. 498.]\n",
            " [ 61. 470.]\n",
            " [  7. 466.]\n",
            " [ 68. 447.]\n",
            " [  1. 452.]] New non zero [[ 63.11891583 498.66797067]\n",
            " [ 61.97164294 469.41297414]\n",
            " [ 15.07623203 466.31798375]\n",
            " [ 71.21833524 444.86908809]\n",
            " [  0.         452.47265456]] Bbox: [[  0.       444.401   ]\n",
            " [ 79.830475 640.7544  ]]\n",
            "COUNT non zeros [11057 11157]\n",
            "After Transformation: Nonzero  [[ 63.11891583 498.66797067]\n",
            " [ 61.97164294 469.41297414]\n",
            " [ 15.07623203 466.31798375]\n",
            " [ 71.21833524 444.86908809]\n",
            " [  0.           0.        ]] BBox  [[  3.07726124 444.07929611]\n",
            " [ 76.38564558 635.47846322]]\n",
            "feature number 5\n",
            "ALLFEAT (0,) (5, 1, 2)\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 8 <class 'numpy.int64'>\n",
            "get 2  K 3\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 1 <class 'numpy.int64'>\n",
            "get 2  K 3\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 8 <class 'numpy.int64'>\n",
            "get 2  K 3\n",
            "8 running: 4\n",
            "8 running: 5\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 4 <class 'numpy.int64'>\n",
            "get 1  K 5\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 2 <class 'numpy.int64'>\n",
            "get 1  K 5\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 5\n",
            "InterNum  0  maskNum  2458\n",
            "masks do not match but will have to look more : cnt 1\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 1 <class 'numpy.int64'>\n",
            "get 2  K 5\n",
            "DICT {1: 2, 2: 1, 4: 1, 8: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 5\n",
            "InterNum  2387  maskNum  2458\n",
            "masks match\n",
            "8 running: 6\n",
            "8 running: 7\n",
            "8 running: 8\n",
            "Count 1\n",
            "########save frame 2 ###########\n",
            "ALL classes []\n",
            "old count 9  and count (7,)\n",
            "old classes [9 4 2 9 1 9 8 1 8]\n",
            "7 running: 0\n",
            "DICT {1: 2, 2: 1, 4: 2, 9: 2}\n",
            "Class Num: 2 <class 'numpy.int64'>\n",
            "get 1  K 0\n",
            "DICT {1: 2, 2: 1, 4: 2, 9: 2}\n",
            "Class Num: 4 <class 'numpy.int64'>\n",
            "get 2  K 0\n",
            "DICT {1: 2, 2: 1, 4: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 0\n",
            "InterNum  1205  maskNum  9760\n",
            "masks do not match but will have to look more : cnt 1\n",
            "DICT {1: 2, 2: 1, 4: 2, 9: 2}\n",
            "Class Num: 1 <class 'numpy.int64'>\n",
            "get 2  K 0\n",
            "DICT {1: 2, 2: 1, 4: 2, 9: 2}\n",
            "Class Num: 9 <class 'numpy.int64'>\n",
            "get 2  K 0\n",
            "InterNum  0  maskNum  9760\n",
            "masks do not match : optical flow to put mask on pic\n",
            "Transform mask: feature points (0,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ca198c750f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrawVideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/CIS581/ImageSegmentation/test videos/cabc30fc-eb673c5a.mov\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CIS581/ImageSegmentation/optresults\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CIS581/ImageSegmentation/optresults\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mobjectTrackingNew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawVideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-953a574daaa2>\u001b[0m in \u001b[0;36mobjectTrackingNew\u001b[0;34m(rawVideo)\u001b[0m\n\u001b[1;32m    142\u001b[0m                   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"masks do not match : optical flow to put mask on pic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0mall_featNum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meraseObject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitNF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe_old\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_featNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_bboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_bboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0meraseObject\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                       \u001b[0mtmp_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CIS581/ImageSegmentation/optical_flow.py\u001b[0m in \u001b[0;36mtransformMask\u001b[0;34m(initFeatureNum, frame, frame_old, all_featNum, all_features, all_bboxes, all_coords, all_classes, features, old_bbox, old_coord, old_classes, H, W, N)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransformMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitFeatureNum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe_old\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_featNum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_bboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_coord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transform mask: feature points\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mtmp_new_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimateAllTranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe_old\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mtmp_new_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_new_features\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp_new_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mold_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_coord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CIS581/ImageSegmentation/optical_flow.py\u001b[0m in \u001b[0;36mestimateAllTranslation\u001b[0;34m(features, img1, img2)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mnew_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mnew_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimateFeatureTranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;31m#print(\"NEW FEAT\",new_features,new_features.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CIS581/ImageSegmentation/optical_flow.py\u001b[0m in \u001b[0;36mestimateFeatureTranslation\u001b[0;34m(feature, Ix, Iy, img1, img2)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mdx_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mdy_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mimg2_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_new_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdx_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mimg2_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2_shift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CIS581/ImageSegmentation/optical_flow.py\u001b[0m in \u001b[0;36mget_new_img\u001b[0;34m(img, dx, dy)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mnew_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minterp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CIS581/ImageSegmentation/helpers.py\u001b[0m in \u001b[0;36minterp2\u001b[0;34m(v, xq, yq)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mq_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mxq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0myq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqC1IVDSKJqC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}